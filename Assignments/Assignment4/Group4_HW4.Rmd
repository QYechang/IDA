---
title: "Assignment 4 Data Wrangling"
author: "Nicholas Jacob and Zayne Mclaughlin"
date: "2024-09-05"
output: pdf_document
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
library(ggplot2)
library(corrplot)
library(ggfortify)
library(MASS)
library(caret)
library(magrittr)
library(dplyr)
library(HSAUR2)
library(outliers)
library(ggbiplot)
library(GGally)
library(gridExtra)
#library(mice)
library(forcats)
```

1.
```{r}
housingData = read.csv("housingData-1.csv")

housingData <- housingData %>%
  dplyr::mutate(age = YrSold - YearBuilt, ageSinceRemodel = YrSold - YearRemodAdd, ageofGarage = YrSold - GarageYrBlt)
```
1.b.

```{r}
housingNumeric <- housingData %>% 
  dplyr::select(where(is.numeric))

```
1.c.
```{r}
housingFactor <- housingData %>% 
  dplyr::select(where(is.character))%>%
  mutate_all(factor)
```

1.d.
```{r}
glimpse(housingFactor)
```
```{r}
glimpse(housingNumeric)
```
1.e.

The following functions create a $Q_1$ and $Q_3$ function that takes a vector $x$ and an optional `na.rm` which by default has been set to true.  Then it calls the `quantile` function and extracts the second and the fourth element from the five number summary giving just the $Q_1$ and $Q_3$.
```{r}
Q1<-function(x,na.rm=TRUE) {
quantile(x,na.rm=na.rm)[2]
}
Q3<-function(x,na.rm=TRUE) {
quantile(x,na.rm=na.rm)[4]
}
```

1.f. Here is a function that will do the numeric computations for us.
```{r}
myNumericSummary <- function(x){
  c(length(x), n_distinct(x), sum(is.na(x)), mean(x, na.rm=TRUE),
  min(x,na.rm=TRUE), Q1(x,na.rm=TRUE), median(x,na.rm=TRUE), Q3(x,na.rm=TRUE),
  max(x,na.rm=TRUE), sd(x,na.rm=TRUE))
}
```

1.g.

I think this is what was intended.  I did get this to work with `summarise_all` as well without the additional commands of `across` and `where`
```{r}
numericSummary <- housingNumeric %>%
  summarise(across(where(is.numeric),myNumericSummary))

glimpse(numericSummary)
```
1.h.
```{r}
numericSummary <-cbind(stat=c("n","unique","missing","mean","min","Q1","median",
                              "Q3","max","sd"),numericSummary)
```

2.a.

I notice two examples of skewed data, `YearBuilt` and `SalePrice`.  The skews are in opposite directions so that is fun!  First I try the Year built.  Here is the visualization.

```{r}
yb <- ggplot(data = housingData, aes(x = YearBuilt)) +
  geom_histogram() +
  ggtitle("Year Built is Skewed") +
  xlab("Year Built")
yb
```

Very bimodal and skewed to the current time.  Apply the `boxcox` function.

```{r}
b<-boxcox(lm(housingData$YearBuilt~1), lambda = seq(-4,50,1/10)) #tweaked the limits until found the correct parameter for this
lambda <- b$x[which.max(b$y)] #find the max
lambda
```

This is the optimal $\lambda$.

```{r}
mytitle <- paste("Boxcox with lambda=", lambda)
ybm <- housingData %>%
  mutate(YearBuiltMod = (YearBuilt^lambda-1)/lambda) %>%
  ggplot( aes(x = YearBuiltMod)) +
  geom_histogram() +
  ggtitle(mytitle) +
  xlab("Year Built")

grid.arrange(yb,ybm, nrow = 1)
```
This is much better but by no means perfect.  Looks like the year built was quite a difficult column due to the bi-modal distribution.

I am going to look at the Sale Price.  These are notorious for not being normal.

```{r}
sp <- ggplot(data = housingData, aes(x = SalePrice)) +
  geom_histogram() +
  ggtitle("Sale Price is Skewed") +
  xlab("Sale Price")

sp
```
```{r}
b<-boxcox(lm(housingData$SalePrice~1), lambda = seq(-4,4,1/10))
lambda <- b$x[which.max(b$y)]
lambda
```

```{r}
mytitle <- paste("Boxcox with lambda=", lambda)
spm <- housingData %>%
  mutate(SalePriceMod = (SalePrice^lambda -1)/lambda) %>%
  ggplot( aes(x = SalePriceMod)) +
  geom_histogram() +
  ggtitle(mytitle) +
  xlab("Sale Price")

grid.arrange(sp,spm, nrow = 1)
```

That looks much better.  Quite normal and ready for analysis.

2.b.i.

Looking to `LotFrontage`, we see lots of missing values.
```{r}
missing <- is.na(housingData$LotFrontage) #find the missing values
sum(missing) #give a total
```
We impute first by replacing it with the mean.

```{r}
avg <- mean(housingData$LotFrontage, na.rm = TRUE) #get the mean before imputing
housingData <- housingData %>%
  mutate(LFMean = if_else(is.na(LotFrontage), avg,LotFrontage)) #create a new column imputed with the mean
  
```

b.ii.

Now we'll impute with a linear regression and some error depending on that regression.  Since we are trying to predict something about the lot, I keep only variables with information about the outside of the house.  I could not use `Alley` because it did not have enough levels to fit the linear model.  I could not use `LotShape` due to some shapes not being in the training data.  I could not use `Fence` either due to many missing values.
```{r}
names(housingData)[c(4,5,8,9)] #find the names of variables that will work 
fit <- lm(LotFrontage ~ ., data=housingData[,names(housingData)[c(4,5,8,9)]]) #do linear fit
summary(fit)
```
We see that the fit is decent with most of the variables that we have used showing signifigance.

Now we make predictions and impute.
```{r}
pred <- predict(fit,housingData[,names(housingData)[c(4,5,8,9)]] ) #create predictions
se <- summary(fit)[[6]] #standard error of the fit
housingData <- housingData%>%
  mutate(LFLM = if_else(is.na(LotFrontage),pred + rnorm(length(pred),0,se),LotFrontage)) #add the new column
```

b.iii.

We use the `mice` package for predictive mean matching.  Here I used LotArea and SalePrice to build the model.  This package would not work with any missing values.
```{r}
housingData$LFPMM <- housingData$LotFrontage #create a new column with all the values
housingData[missing,"LFPMM"] =  mice.impute.pmm(housingData$LotFrontage,!missing,housingData[,names(housingData)[c(5,74)]]) #replace na's with predictions
```

b.iv.

Time to visualize.

```{r}
colors <- c("Original" = "blue", "Impute with Mean" = "yellow", "Impute with Regression" = "red", "Impute with PMM" = "orange")
g1 <- ggplot(housingData)+
  geom_histogram(aes(x = LotFrontage, fill = "Original"),alpha = 0.5) +
  geom_histogram(aes(x = LFMean, fill = "Impute with Mean"),alpha = 0.5) +
  labs(title = "Impute by Mean",  fill = "legend")+
  scale_color_manual(values = colors) +
  coord_cartesian(xlim = c(0,350))
g2 <- ggplot(housingData)+
  geom_histogram(aes(x = LotFrontage, fill = "Original"),alpha = 0.5) +
  geom_histogram(aes(x = LFLM, fill = "Impute with Regression"),alpha = 0.5) +
  labs(title = "Impute by Regression",  fill = "legend")+
  scale_color_manual(values = colors) +
  coord_cartesian(xlim = c(0,350))
g3 <- ggplot(housingData)+
  geom_histogram(aes(x = LotFrontage, fill = "Original"),alpha = 0.5) +
  geom_histogram(aes(x = LFPMM, fill = "Impute with PMM"),alpha = 0.5) +
  labs(title = "Impute by PMM",  fill = "legend")+
  scale_color_manual(values = colors) +
  coord_cartesian(xlim = c(0,350))

grid.arrange(g1,g2,g3)
```

We see some of what was expected.  The mean imputation really returns that same value a lot.  The regression imputation is better and the pmm seems best.  

2.c.
Create 5 levels for the variable `Exterior1st`.  Here is the original counts sorted.
```{r}
housingData %>%
  dplyr::count(Exterior1st, sort = TRUE) #somewhere I masked the dplyr count function
```
```{r}
housingData %>%
  mutate(Exterior1st = fct_lump(Exterior1st,n=4)) %>% #this will create 4 categories with the 5th being other
  dplyr::count(Exterior1st, sort = TRUE)
```

2.d.i.

We use `dplyr` again for this noticing that some of the functions need to be called with package name.
```{r}
housingData %>% 
  dplyr::group_by(Neighborhood) %>%
  dplyr::summarise(average = mean(SalePrice)) %>%
  arrange(desc(average))
```

2.d.ii.
Create a boxplot of the saleprice with neighborhoods.

```{r}
ggplot(housingData, aes(y = SalePrice, x = Neighborhood)) +
  geom_boxplot()
```

2.d.iii.
```{r}
housingData <- housingData %>%
  mutate(Neighborhood = factor(Neighborhood)) %>% #turn the data into a factor
  mutate(Neighborhood = fct_reorder(Neighborhood,SalePrice, .desc = TRUE)) #reorder the data uses median by default

```
2.d.iv.

Since the data has been reordered, we only need to call ggplot.
```{r}
housingData %>%
  ggplot(aes(x= Neighborhood, y = SalePrice)) +
  geom_boxplot() +
  labs(title = "Sale Price Box Plot", x = "Neighborhood")+
  scale_x_discrete(guide = guide_axis(n.dodge=3)) #just to get the variables to dodge
```


```{r, include = FALSE}
housingData %>%
  ggplot(aes(fct_reorder(Neighborhood,SalePrice, .desc = TRUE),SalePrice)) + #uses median by default
  geom_boxplot() +
  labs(x = "Neighborhood")+
  scale_x_discrete(guide = guide_axis(n.dodge=3)) #just to get the variables to dodge
  
```
